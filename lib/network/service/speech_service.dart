import 'dart:async';
import 'dart:developer';
import 'dart:math' as math;
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:flutter_tts/flutter_tts.dart';
import 'package:google_speech/speech_client_authenticator.dart';
import 'package:google_speech/speech_to_text.dart';
import 'package:google_speech/google_speech.dart';
import 'package:google_speech/generated/google/cloud/speech/v1/cloud_speech.pbgrpc.dart' as grpc;
import 'package:permission_handler/permission_handler.dart';
import 'package:injectable/injectable.dart';

@singleton
class SpeechService {
  FlutterTts? _flutterTts;
  SpeechToText? _speechToText;
  bool _isInitialized = false;
  bool _isListening = false;
  StreamController<String>? _speechController;
  StreamSubscription<grpc.StreamingRecognizeResponse>? _recognitionSubscription;
  
  // Real microphone recording with platform channels
  static const MethodChannel _microphoneChannel = MethodChannel('microphone_channel');
  static const EventChannel _audioDataChannel = EventChannel('audio_data_channel');
  
  // Audio simulation for testing (remove in production)
  Timer? _audioSimulationTimer;
  bool _isSimulatingAudio = false;
  
  // Manual mode for testing
  bool _isManualMode = false; // Set to false for real speech recognition
  Timer? _manualDetectionTimer;
  
  // Real-time audio processing
  StreamController<List<int>>? _realAudioStream;
  bool _isRealAudioActive = false;
  
  // Audio data subscription with correct type
  StreamSubscription<dynamic>? _audioDataSubscription;
  
  // Disable simulation mode completely
  bool _enableSimulation = false; // Set to false to disable all simulation

  // Enhanced command detection
  final Map<String, List<String>> _commandPatterns = {
    'increase_quantity': [
      'tƒÉng s·ªë l∆∞·ª£ng',
      'tƒÉng s·ªë',
      'th√™m s·ªë l∆∞·ª£ng',
      'tƒÉng l√™n',
      'tƒÉng th√™m',
      'c·ªông th√™m',
      'tƒÉng m·ªôt',
      'tƒÉng hai',
      'tƒÉng ba',
      'tƒÉng b·ªën',
      'tƒÉng nƒÉm',
    ],
    'decrease_quantity': [
      'gi·∫£m s·ªë l∆∞·ª£ng',
      'gi·∫£m s·ªë',
      'b·ªõt s·ªë l∆∞·ª£ng',
      'gi·∫£m xu·ªëng',
      'gi·∫£m ƒëi',
      'tr·ª´ ƒëi',
      'gi·∫£m m·ªôt',
      'gi·∫£m hai',
      'gi·∫£m ba',
      'gi·∫£m b·ªën',
      'gi·∫£m nƒÉm',
    ],
    'add_to_cart': [
      'th√™m v√†o gi·ªè',
      'th√™m gi·ªè h√†ng',
      'cho v√†o gi·ªè',
      'b·ªè v√†o gi·ªè',
      'th√™m v√†o gi·ªè h√†ng',
      'mua s·∫£n ph·∫©m',
      'th√™m s·∫£n ph·∫©m',
      'ƒë·∫∑t h√†ng',
    ],
    'buy_now': [
      'mua ngay',
      'mua lu√¥n',
      'mua ngay l·∫≠p t·ª©c',
      'thanh to√°n ngay',
      'mua ngay b√¢y gi·ªù',
      'ƒë·∫∑t mua ngay',
    ],
    'read_info': [
      'ƒë·ªçc th√¥ng tin',
      'th√¥ng tin s·∫£n ph·∫©m',
      'm√¥ t·∫£ s·∫£n ph·∫©m',
      'chi ti·∫øt s·∫£n ph·∫©m',
      'th√¥ng tin chi ti·∫øt',
      'ƒë·ªçc m√¥ t·∫£',
      'th√¥ng tin g√¨',
    ],
    'read_price': [
      'ƒë·ªçc gi√°',
      'gi√° bao nhi√™u',
      'gi√° s·∫£n ph·∫©m',
      'gi√° ti·ªÅn',
      'bao nhi√™u ti·ªÅn',
      'gi√° c·∫£',
      'ƒë·ªçc gi√° c·∫£',
    ],
    'instructions': [
      'h∆∞·ªõng d·∫´n',
      'h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng',
      'c√°ch s·ª≠ d·ª•ng',
      'tr·ª£ gi√∫p',
      'gi√∫p ƒë·ª°',
      'h∆∞·ªõng d·∫´n gi·ªçng n√≥i',
      'c√°ch d√πng',
    ],
  };

  // Initialize TTS and Speech Recognition
  Future<void> initialize() async {
    log('üé§ [Speech] initialize() called');
    
    if (_isInitialized) {
      log('‚úÖ [Speech] Already initialized, skipping');
      return;
    }

    try {
      log('üîÑ [Speech] Starting initialization...');
      
      // Initialize TTS
      log('üîä [Speech] Initializing TTS...');
      _flutterTts = FlutterTts();
      await _flutterTts!.setLanguage('vi-VN');
      await _flutterTts!.setSpeechRate(0.6); // Slower for elderly
      await _flutterTts!.setVolume(1.0);
      await _flutterTts!.setPitch(1.0);
      log('‚úÖ [Speech] TTS initialized successfully');

      // Initialize microphone recorder
      log('üé§ [Speech] Initializing microphone recorder...');
      
      // Check microphone permission
      if (!await checkMicrophonePermission()) {
        log('‚ùå [Speech] Microphone permission not granted');
        return;
      }
      log('‚úÖ [Speech] Microphone recorder initialized');

      // Initialize Speech Recognition
      log('üéØ [Speech] Initializing Speech Recognition...');
      await _initializeSpeechRecognition();

      _isInitialized = true;
      log('üéâ [Speech] Speech service fully initialized');
    } catch (e) {
      log('‚ùå [Speech] Error during initialization: $e');
      log('‚ùå [Speech] Stack trace: ${StackTrace.current}');
    }
  }

  // Initialize Google Speech Recognition
  Future<void> _initializeSpeechRecognition() async {
    log('üîß [Speech] _initializeSpeechRecognition() called');
    
    try {
      // Check microphone permission first
      log('üîç [Speech] Checking microphone permission...');
      if (!await checkMicrophonePermission()) {
        log('‚ùå [Speech] Microphone permission not granted');
        return;
      }
      log('‚úÖ [Speech] Microphone permission granted');

      // Create speech client using service account (recommended for production)
      try {
        log('üìÅ [Speech] Loading service account from assets...');
        
        // Option 1: Use service account from assets (recommended)
        final serviceAccountJson = await rootBundle.loadString('assets/service_account.json');
        log('üìÑ [Speech] Service account JSON loaded, length: ${serviceAccountJson.length}');
        
        // Check if service account is properly configured
        if (serviceAccountJson.contains('YOUR_PRIVATE_KEY_HERE') || 
            serviceAccountJson.contains('your_private_key_id')) {
          log('‚ö†Ô∏è [Speech] Service account appears to be template - using fallback mode');
          throw Exception('Service account not properly configured');
        }
        
        final serviceAccount = ServiceAccount.fromString(serviceAccountJson);
        log('‚úÖ [Speech] Service account parsed successfully');
        
        _speechToText = SpeechToText.viaServiceAccount(serviceAccount);
        log('‚úÖ [Speech] SpeechToText client created with service account');
        
        log('üéâ [Speech] Speech recognition initialized successfully with service account');
      } catch (e) {
        log('‚ùå [Speech] Error creating speech client: $e');
        log('‚ùå [Speech] Stack trace: ${StackTrace.current}');
        log('Please check assets/service_account.json file - it should contain real credentials');
        
        // Fallback: Enable simulation mode for testing
        log('üîÑ [Speech] Enabling simulation mode for testing...');
        _enableSimulation = true;
        _speechToText = null;
      }
    } catch (e) {
      log('‚ùå [Speech] Error initializing speech recognition: $e');
      log('‚ùå [Speech] Stack trace: ${StackTrace.current}');
    }
  }

  // Start listening for voice commands
  Future<void> startListening({
    required Function(String) onResult,
    required Function(String) onError,
    required VoidCallback onListeningComplete,
  }) async {
    log('üé§ [Speech] startListening() called');
    
    if (!_isInitialized) {
      log('‚ùå [Speech] Service not initialized');
      onError('Speech service not initialized');
      return;
    }

    if (_isListening) {
      log('‚ö†Ô∏è [Speech] Already listening, cannot start again');
      onError('Already listening');
      return;
    }

    try {
      log('üîç [Speech] Checking microphone permission...');
      // Check permission again
      if (!await checkMicrophonePermission()) {
        log('‚ùå [Speech] Microphone permission denied');
        onError('Microphone permission required');
        return;
      }
      log('‚úÖ [Speech] Microphone permission granted');

      _setListeningState(true);
      log('üéØ [Speech] Set listening state to true');

      // Check if we have real Google Speech API client
      if (_speechToText != null && !_enableSimulation) {
        await _startRealSpeechRecognition(onResult, onError, onListeningComplete);
      } else if (_enableSimulation) {
        // Use simulation mode for testing (disabled by default)
        await _startSimulatedSpeechRecognition(onResult, onError, onListeningComplete);
      } else {
        // No Google Speech API and simulation disabled
        onError('Speech recognition not available. Please check Google Cloud configuration.');
        _setListeningState(false);
      }

    } catch (e) {
      log('‚ùå [Speech] Error starting speech recognition: $e');
      log('‚ùå [Speech] Stack trace: ${StackTrace.current}');
      onError('L·ªói kh·ªüi ƒë·ªông nh·∫≠n di·ªán gi·ªçng n√≥i: $e');
      _setListeningState(false);
    }
  }

  // Start real Google Speech API recognition
  Future<void> _startRealSpeechRecognition(
    Function(String) onResult,
    Function(String) onError,
    VoidCallback onListeningComplete,
  ) async {
    log('üöÄ [Speech] Starting real Google Speech API recognition...');
    
    // Configure recognition using the correct types
    log('‚öôÔ∏è [Speech] Configuring recognition...');
    final config = StreamingRecognitionConfig(
      config: RecognitionConfig(
        encoding: AudioEncoding.LINEAR16,
        model: RecognitionModel.basic,
        enableAutomaticPunctuation: true,
        sampleRateHertz: 16000,
        languageCode: 'vi-VN', // Vietnamese
        maxAlternatives: 3, // Get multiple alternatives for better accuracy
        enableWordTimeOffsets: false,
      ),
      interimResults: true, // Get interim results for better UX
      singleUtterance: false, // Allow continuous listening
    );
    log('‚úÖ [Speech] Recognition config created');

    // Create audio stream for real microphone input
    log('üéµ [Speech] Creating audio stream...');
    final audioStream = StreamController<List<int>>();
    log('‚úÖ [Speech] Audio stream created');
    
    // Start listening
    log('üöÄ [Speech] Starting streamingRecognize...');
    final responseStream = _speechToText!.streamingRecognize(config, audioStream.stream);
    log('‚úÖ [Speech] streamingRecognize started successfully');
    
    _recognitionSubscription = responseStream.listen(
      (response) {
        log('üì° [Speech] Received response: ${response.toString()}');
        if (response.results.isNotEmpty) {
          final result = response.results.first;
          log('üéØ [Speech] First result: isFinal=${result.isFinal}, alternatives=${result.alternatives.length}');
          
          // Process all alternatives for better accuracy
          for (final alternative in result.alternatives) {
            final transcript = alternative.transcript.trim();
            final confidence = alternative.confidence;
            
            log('üéØ [Speech] Alternative: "$transcript" (confidence: ${(confidence * 100).toStringAsFixed(1)}%)');
            
            // Check if this is a valid command
            final commandType = _detectCommand(transcript);
            if (commandType != 'unknown') {
              log('üéâ [Speech] Valid command detected: $commandType from "$transcript"');
              onResult(transcript);
              return; // Stop processing alternatives
            }
          }
          
          // If final result and no valid command found, report unknown command
          if (result.isFinal) {
            final transcript = result.alternatives.first.transcript.trim();
            log('‚ùì [Speech] No valid command found in: "$transcript"');
            onError('Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c l·ªánh: "$transcript". Vui l√≤ng th·ª≠ l·∫°i.');
          }
        } else {
          log('‚ö†Ô∏è [Speech] Response has no results');
        }
      },
      onError: (error) {
        log('‚ùå [Speech] Speech recognition error: $error');
        log('‚ùå [Speech] Error type: ${error.runtimeType}');
        
        // Provide more specific error messages
        String errorMessage = 'Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i';
        if (error.toString().contains('network')) {
          errorMessage = 'L·ªói k·∫øt n·ªëi m·∫°ng. Vui l√≤ng ki·ªÉm tra internet.';
        } else if (error.toString().contains('permission')) {
          errorMessage = 'Kh√¥ng c√≥ quy·ªÅn truy c·∫≠p microphone. Vui l√≤ng c·∫•p quy·ªÅn.';
        } else if (error.toString().contains('timeout')) {
          errorMessage = 'H·∫øt th·ªùi gian ch·ªù. Vui l√≤ng th·ª≠ l·∫°i.';
        } else if (error.toString().contains('quota')) {
          errorMessage = 'ƒê√£ h·∫øt h·∫°n s·ª≠ d·ª•ng API. Vui l√≤ng th·ª≠ l·∫°i sau.';
        }
        
        onError(errorMessage);
        stopListening();
        onListeningComplete();
      },
      onDone: () {
        log('‚úÖ [Speech] Speech recognition stream completed');
        // Only call onListeningComplete if we're still listening
        if (_isListening) {
          stopListening();
          onListeningComplete();
        }
      },
    );

    log('üé§ [Speech] Successfully started real speech recognition');
    
    // Start real microphone recording instead of simulation
    await _startRealMicrophoneRecording(audioStream);
  }

  // Enhanced command detection with fuzzy matching
  String _detectCommand(String transcript) {
    final lowerTranscript = transcript.toLowerCase().trim();
    log('üîç [Speech] Detecting command in: "$lowerTranscript"');
    
    // Check each command pattern
    for (final entry in _commandPatterns.entries) {
      final commandType = entry.key;
      final patterns = entry.value;
      
      for (final pattern in patterns) {
        // Exact match
        if (lowerTranscript == pattern) {
          log('‚úÖ [Speech] Exact match found: $pattern -> $commandType');
          return commandType;
        }
        
        // Contains match
        if (lowerTranscript.contains(pattern)) {
          log('‚úÖ [Speech] Contains match found: $pattern in "$lowerTranscript" -> $commandType');
          return commandType;
        }
        
        // Fuzzy match for common variations
        if (_fuzzyMatch(lowerTranscript, pattern)) {
          log('‚úÖ [Speech] Fuzzy match found: $pattern ~ "$lowerTranscript" -> $commandType');
          return commandType;
        }
      }
    }
    
    log('‚ùå [Speech] No command pattern matched: "$lowerTranscript"');
    return 'unknown';
  }

  // Fuzzy matching for Vietnamese commands
  bool _fuzzyMatch(String input, String pattern) {
    // Remove common Vietnamese variations
    final normalizedInput = _normalizeVietnamese(input);
    final normalizedPattern = _normalizeVietnamese(pattern);
    
    // Check if normalized strings match
    if (normalizedInput.contains(normalizedPattern) || 
        normalizedPattern.contains(normalizedInput)) {
      return true;
    }
    
    // Check for common typos/variations
    final inputWords = normalizedInput.split(' ');
    final patternWords = normalizedPattern.split(' ');
    
    // If at least 70% of words match, consider it a match
    int matchCount = 0;
    for (final inputWord in inputWords) {
      for (final patternWord in patternWords) {
        if (inputWord == patternWord || 
            inputWord.contains(patternWord) || 
            patternWord.contains(inputWord)) {
          matchCount++;
          break;
        }
      }
    }
    
    final matchRatio = matchCount / math.max(inputWords.length, patternWords.length);
    return matchRatio >= 0.7;
  }

  // Normalize Vietnamese text for better matching
  String _normalizeVietnamese(String text) {
    return text
        .replaceAll('√†', 'a').replaceAll('√°', 'a').replaceAll('·∫£', 'a').replaceAll('√£', 'a').replaceAll('·∫°', 'a')
        .replaceAll('ƒÉ', 'a').replaceAll('·∫±', 'a').replaceAll('·∫Ø', 'a').replaceAll('·∫≥', 'a').replaceAll('·∫µ', 'a').replaceAll('·∫∑', 'a')
        .replaceAll('√¢', 'a').replaceAll('·∫ß', 'a').replaceAll('·∫•', 'a').replaceAll('·∫©', 'a').replaceAll('·∫´', 'a').replaceAll('·∫≠', 'a')
        .replaceAll('√®', 'e').replaceAll('√©', 'e').replaceAll('·∫ª', 'e').replaceAll('·∫Ω', 'e').replaceAll('·∫π', 'e')
        .replaceAll('√™', 'e').replaceAll('·ªÅ', 'e').replaceAll('·∫ø', 'e').replaceAll('·ªÉ', 'e').replaceAll('·ªÖ', 'e').replaceAll('·ªá', 'e')
        .replaceAll('√¨', 'i').replaceAll('√≠', 'i').replaceAll('·ªâ', 'i').replaceAll('ƒ©', 'i').replaceAll('·ªã', 'i')
        .replaceAll('√≤', 'o').replaceAll('√≥', 'o').replaceAll('·ªè', 'o').replaceAll('√µ', 'o').replaceAll('·ªç', 'o')
        .replaceAll('√¥', 'o').replaceAll('·ªì', 'o').replaceAll('·ªë', 'o').replaceAll('·ªï', 'o').replaceAll('·ªó', 'o').replaceAll('·ªô', 'o')
        .replaceAll('∆°', 'o').replaceAll('·ªù', 'o').replaceAll('·ªõ', 'o').replaceAll('·ªü', 'o').replaceAll('·ª°', 'o').replaceAll('·ª£', 'o')
        .replaceAll('√π', 'u').replaceAll('√∫', 'u').replaceAll('·ªß', 'u').replaceAll('≈©', 'u').replaceAll('·ª•', 'u')
        .replaceAll('∆∞', 'u').replaceAll('·ª´', 'u').replaceAll('·ª©', 'u').replaceAll('·ª≠', 'u').replaceAll('·ªØ', 'u').replaceAll('·ª±', 'u')
        .replaceAll('·ª≥', 'y').replaceAll('√Ω', 'y').replaceAll('·ª∑', 'y').replaceAll('·ªπ', 'y').replaceAll('·ªµ', 'y')
        .replaceAll('ƒë', 'd')
        .toLowerCase();
  }

  // Start simulated speech recognition for testing
  Future<void> _startSimulatedSpeechRecognition(
    Function(String) onResult,
    Function(String) onError,
    VoidCallback onListeningComplete,
  ) async {
    log('üé≠ [Speech] Starting simulated speech recognition...');
    
    if (_isManualMode) {
      log('üéÆ [Speech] Manual mode enabled - waiting for manual trigger');
      return; // Don't auto-detect in manual mode
    }
    
    // Simulate speech recognition with predefined commands
    final commands = [
      'TƒÉng s·ªë l∆∞·ª£ng',
      'Gi·∫£m s·ªë l∆∞·ª£ng', 
      'Th√™m v√†o gi·ªè',
      'Mua ngay',
      'ƒê·ªçc th√¥ng tin',
      'ƒê·ªçc gi√°',
      'H∆∞·ªõng d·∫´n',
    ];
    
    // Simulate detection after 3 seconds (only once)
    Future.delayed(const Duration(seconds: 3), () {
      if (_isListening) {
        final randomCommand = commands[DateTime.now().millisecondsSinceEpoch % commands.length];
        log('üé≠ [Speech] Simulated command detected: "$randomCommand"');
        onResult(randomCommand);
        
        // Don't continue automatically - wait for user to speak again
        log('üé≠ [Speech] Simulation completed, waiting for real input...');
      }
    });
    
    log('üé≠ [Speech] Simulated speech recognition started (will detect once after 3s)');
  }

  // Manual trigger for testing (call this when you want to simulate detection)
  void triggerManualDetection(Function(String) onResult) {
    if (!_isListening || !_isManualMode) return;
    
    log('üéÆ [Speech] Manual detection triggered');
    
    final commands = [
      'TƒÉng s·ªë l∆∞·ª£ng',
      'Gi·∫£m s·ªë l∆∞·ª£ng', 
      'Th√™m v√†o gi·ªè',
      'Mua ngay',
      'ƒê·ªçc th√¥ng tin',
      'ƒê·ªçc gi√°',
      'H∆∞·ªõng d·∫´n',
    ];
    
    final randomCommand = commands[DateTime.now().millisecondsSinceEpoch % commands.length];
    log('üé≠ [Speech] Manual command detected: "$randomCommand"');
    onResult(randomCommand);
  }

  // Toggle manual mode
  void toggleManualMode() {
    _isManualMode = !_isManualMode;
    log('üéÆ [Speech] Manual mode ${_isManualMode ? 'enabled' : 'disabled'}');
  }

  // Get current mode
  bool get isManualMode => _isManualMode;
  
  // Toggle simulation mode (for development/testing only)
  void toggleSimulationMode() {
    _enableSimulation = !_enableSimulation;
    log('üé≠ [Speech] Simulation mode ${_enableSimulation ? 'enabled' : 'disabled'}');
  }
  
  // Get simulation mode status
  bool get isSimulationEnabled => _enableSimulation;

  // Start audio simulation for testing
  void _startAudioSimulation(StreamController<List<int>> audioStream) {
    if (_isSimulatingAudio) return;
    
    _isSimulatingAudio = true;
    log('üéµ [Speech] Starting audio simulation...');
    
    // Simulate audio data every 100ms
    _audioSimulationTimer = Timer.periodic(const Duration(milliseconds: 100), (timer) {
      if (!_isListening || !_isSimulatingAudio) {
        timer.cancel();
        _isSimulatingAudio = false;
        return;
      }
      
      // Generate simulated audio data (16-bit PCM, 16kHz)
      final audioData = _generateSimulatedAudioData();
      audioStream.add(audioData);
      
      // Log only occasionally to avoid spam
      if (DateTime.now().millisecondsSinceEpoch % 1000 < 100) {
        log('üéµ [Speech] Sending simulated audio data: ${audioData.length} bytes');
      }
    });
  }

  // Generate simulated audio data
  List<int> _generateSimulatedAudioData() {
    // Generate 800 samples (50ms at 16kHz) of simulated audio
    final samples = <int>[];
    final sampleCount = 800;
    
    for (int i = 0; i < sampleCount; i++) {
      // Generate a simple sine wave pattern
      final time = DateTime.now().millisecondsSinceEpoch / 1000.0;
      final frequency = 440.0; // A4 note
      final amplitude = 0.3; // Reduced amplitude
      
      final sample = (amplitude * 32767 * (0.5 + 0.5 * math.sin(time * frequency))).round();
      
      // Convert to 16-bit little-endian
      samples.add(sample & 0xFF);
      samples.add((sample >> 8) & 0xFF);
    }
    
    return samples;
  }

  // Stop listening
  void stopListening() {
    if (!_isListening) return;

    try {
      log('üõë [Speech] Stopping speech recognition...');
      
      // Stop real recognition
      _recognitionSubscription?.cancel();
      _recognitionSubscription = null;
      
      // Stop real microphone recording
      _stopRealMicrophoneRecording();
      
      // Stop audio simulation (fallback)
      _audioSimulationTimer?.cancel();
      _isSimulatingAudio = false;
      
      _setListeningState(false);
      
      log('‚úÖ [Speech] Speech recognition stopped successfully');
      
    } catch (e) {
      log('‚ùå [Speech] Error stopping: $e');
    }
  }

  // Check if currently listening
  bool get isListening => _isListening;

  // Set listening state
  void _setListeningState(bool listening) {
    _isListening = listening;
    log('üîÑ [Speech] Listening state changed to: $listening');
  }

  // Text-to-Speech functionality
  Future<void> speak(String text) async {
    if (!_isInitialized) await initialize();
    
    try {
      log('üîä [Speech] Speaking: "$text"');
      await _flutterTts?.speak(text);
    } catch (e) {
      log('‚ùå [Speech] Error speaking text: $e');
    }
  }

  Future<void> stop() async {
    try {
      log('üîá [Speech] Stopping TTS...');
      await _flutterTts?.stop();
      log('‚úÖ [Speech] TTS stopped');
    } catch (e) {
      log('‚ùå [Speech] Error stopping TTS: $e');
    }
  }

  // Voice commands for specific actions
  Future<void> speakProductInfo(String productName, String price, String description) async {
    final text = 'S·∫£n ph·∫©m $productName. Gi√° $price ƒë·ªìng. $description';
    await speak(text);
  }

  Future<void> speakPriceInfo(String originalPrice, String discountedPrice, String discount) async {
    final text = 'Gi√° g·ªëc $originalPrice ƒë·ªìng. Gi√° khuy·∫øn m√£i $discountedPrice ƒë·ªìng. Gi·∫£m $discount ph·∫ßn trƒÉm';
    await speak(text);
  }

  Future<void> speakQuantityInfo(int quantity) async {
    final text = 'S·ªë l∆∞·ª£ng hi·ªán t·∫°i: $quantity';
    await speak(text);
  }

  Future<void> speakStyleSelection(String styleName, String optionName) async {
    final text = 'ƒê√£ ch·ªçn $styleName: $optionName';
    await speak(text);
  }

  Future<void> speakCartAction(String productName, int quantity) async {
    final text = 'ƒê√£ th√™m $quantity $productName v√†o gi·ªè h√†ng th√†nh c√¥ng';
    await speak(text);
  }

  Future<void> speakBuyNowAction() async {
    final text = 'ƒêang chuy·ªÉn ƒë·∫øn trang thanh to√°n';
    await speak(text);
  }

  Future<void> speakError(String error) async {
    final text = 'C√≥ l·ªói x·∫£y ra: $error';
    await speak(text);
  }

  // Voice instructions for elderly users
  Future<void> speakInstructions() async {
    final text = '''
    H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng gi·ªçng n√≥i:
    - N√≥i "tƒÉng s·ªë l∆∞·ª£ng" ƒë·ªÉ tƒÉng s·ªë l∆∞·ª£ng s·∫£n ph·∫©m
    - N√≥i "gi·∫£m s·ªë l∆∞·ª£ng" ƒë·ªÉ gi·∫£m s·ªë l∆∞·ª£ng s·∫£n ph·∫©m  
    - N√≥i "th√™m v√†o gi·ªè" ƒë·ªÉ th√™m s·∫£n ph·∫©m v√†o gi·ªè h√†ng
    - N√≥i "mua ngay" ƒë·ªÉ mua s·∫£n ph·∫©m ngay l·∫≠p t·ª©c
    - N√≥i "ƒë·ªçc th√¥ng tin" ƒë·ªÉ nghe th√¥ng tin s·∫£n ph·∫©m
    - N√≥i "ƒë·ªçc gi√°" ƒë·ªÉ nghe th√¥ng tin gi√° c·∫£
    ''';
    await speak(text);
  }

  Future<void> speakWelcome() async {
    final text = 'Ch√†o m·ª´ng ƒë·∫øn v·ªõi trang chi ti·∫øt s·∫£n ph·∫©m. Nh·∫•n n√∫t tr·ª£ l√Ω gi·ªçng n√≥i ƒë·ªÉ nghe h∆∞·ªõng d·∫´n';
    await speak(text);
  }

  // Enhanced voice command processing
  bool processVoiceCommand(String command) {
    final commandType = _detectCommand(command);
    return commandType != 'unknown';
  }

  // Get voice command type with enhanced detection
  String getCommandType(String command) {
    return _detectCommand(command);
  }

  // Check microphone permission
  Future<bool> checkMicrophonePermission() async {
    final status = await Permission.microphone.status;
    
    if (status != PermissionStatus.granted) {
      final result = await Permission.microphone.request();
      return result == PermissionStatus.granted;
    }
    
    return true;
  }

  // Start real microphone recording
  Future<void> _startRealMicrophoneRecording(StreamController<List<int>> audioStream) async {
    try {
      log('üé§ [Speech] Starting real microphone recording...');
      
      // Start recording via platform channel
      await _microphoneChannel.invokeMethod('startRecording');
      log('‚úÖ [Speech] Microphone recording started');
      
      // Listen to audio data stream with proper type handling
      _audioDataSubscription = _audioDataChannel.receiveBroadcastStream().listen(
        (data) {
          if (data is List<int>) {
            audioStream.add(data);
            log('üéµ [Speech] Real audio data: ${data.length} bytes');
          } else if (data is List) {
            // Convert List<dynamic> to List<int> if needed
            try {
              final intList = data.cast<int>();
              audioStream.add(intList);
              log('üéµ [Speech] Converted audio data: ${intList.length} bytes');
            } catch (e) {
              log('‚ùå [Speech] Error converting audio data: $e');
            }
          } else {
            log('‚ö†Ô∏è [Speech] Unexpected audio data type: ${data.runtimeType}');
          }
        },
        onError: (error) {
          log('‚ùå [Speech] Error receiving audio data: $error');
        },
      );
      
      _isRealAudioActive = true;
      log('üé§ [Speech] Real microphone recording active');
      
    } catch (e) {
      log('‚ùå [Speech] Error starting microphone recording: $e');
      log('‚ùå [Speech] Stack trace: ${StackTrace.current}');
      
      // Fallback to simulation if real recording fails
      log('üîÑ [Speech] Falling back to audio simulation...');
      _startAudioSimulation(audioStream);
    }
  }

  // Stop real microphone recording
  Future<void> _stopRealMicrophoneRecording() async {
    if (!_isRealAudioActive) return;
    
    try {
      log('üõë [Speech] Stopping real microphone recording...');
      
      // Stop recording via platform channel
      await _microphoneChannel.invokeMethod('stopRecording');
      
      // Cancel audio data subscription
      _audioDataSubscription?.cancel();
      _audioDataSubscription = null;
      
      _isRealAudioActive = false;
      log('‚úÖ [Speech] Real microphone recording stopped');
      
    } catch (e) {
      log('‚ùå [Speech] Error stopping microphone recording: $e');
    }
  }

  // Convert real amplitude to audio data (placeholder for now)
  List<int> _convertAmplitudeToRealAudio(dynamic amplitude) {
    // Placeholder - will be implemented when we have real amplitude data
    final samples = <int>[];
    final sampleCount = 800; // 50ms at 16kHz
    
    for (int i = 0; i < sampleCount; i++) {
      // Generate placeholder audio data
      final sample = (math.Random().nextDouble() * 65535 - 32767).round();
      
      // Convert to 16-bit little-endian
      samples.add(sample & 0xFF);
      samples.add((sample >> 8) & 0xFF);
    }
    
    return samples;
  }

  // Cleanup
  void dispose() {
    log('üßπ [Speech] Disposing SpeechService...');
    
    _flutterTts?.stop();
    _recognitionSubscription?.cancel();
    _speechController?.close();
    _audioSimulationTimer?.cancel();
    
    // Cleanup microphone recorder
    _stopRealMicrophoneRecording();
    _audioDataSubscription?.cancel();
    
    log('‚úÖ [Speech] SpeechService disposed');
  }
}
